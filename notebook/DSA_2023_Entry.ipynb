{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ASSIGNMENT CONFIG\n",
    "requirements: requirements.txt\n",
    "solutions_pdf: true\n",
    "export_cell:\n",
    "    instructions: \"Upload the generated zip file to the Google sheet please. Uploading work which is not yours will lead to non admittance.\"\n",
    "generate: \n",
    "    pdf: false\n",
    "    filtering: false\n",
    "    pagebreaks: true\n",
    "    zips: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1DroRwx3ENZ"
   },
   "source": [
    "## DSA 2023 Summer School Admittance Check\n",
    "\n",
    "Thanks for your interest in attending DSA Kigali 2023. To attend the summer school you have to have some level of basic Python proficiency. Completing the following notebook should ensure you have the right kind of background to benefit maximally from the Summer School. See you in Kigali!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7Upwjh9U3ENa"
   },
   "outputs": [],
   "source": [
    "# Run these once ... Just in case \n",
    "#!pip install nose \n",
    "#!pip install otter-grader\n",
    "import IPython\n",
    "from IPython import get_ipython\n",
    "# Import the good stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nose.tools import assert_equal\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "vBJliosn3ENc"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ibmmx8r3ENc"
   },
   "source": [
    "**Question 1:** Write a Python function to return a tuple of primes and non primes given an integer input "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "EXaFYdNh3ENc"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CWjGPqaO3ENc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following are the prime and non prime numbers smaller than or equal to 30\n",
      "((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "def sieve(num):\n",
    "    prime = [True for i in range(num+1)]\n",
    "    prime_list = []\n",
    "    not_prime_list = []\n",
    "    \n",
    "    # boolean array\n",
    "    p = 2\n",
    "    while (p * p <= num):\n",
    "\n",
    "        # If prime[p] is not\n",
    "        # changed, then it is a prime\n",
    "        if (prime[p] == True):\n",
    "\n",
    "            # Updating all multiples of p\n",
    "            for i in range(p * p, num+1, p):\n",
    "                prime[i] = False\n",
    "        p += 1\n",
    "   \n",
    "    p = 2\n",
    "    # Create the lists \n",
    "    for p in range(2, num+1):\n",
    "        if prime[p]:\n",
    "            prime_list.append(p)\n",
    "        else: \n",
    "            not_prime_list.append(p)\n",
    "   \n",
    "    # Create the tuple \n",
    "    prime_list_tuple = tuple(prime_list)\n",
    "    not_prime_list_tuple = tuple(not_prime_list)\n",
    "    return_tuple = (prime_list_tuple, not_prime_list_tuple)\n",
    "    return(return_tuple)\n",
    "# END SOLUTION\n",
    "num = 30\n",
    "print(\"Following are the prime and non prime numbers smaller than or equal to\", num)\n",
    "print(sieve(num))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "WELGXYcy3ENc"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "-l5Dzy2t3ENc"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jpVT1y5y3ENd"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_primes(sieve):\n",
    "    assert sieve(30) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n",
    "test_primes(sieve)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Sk8NLc_-3ENd"
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "def test_higher_primes(sieve):\n",
    "    assert sieve(100) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100))\n",
    "    assert sieve(200) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 164, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 194, 195, 196, 198, 200))\n",
    "test_higher_primes(sieve) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "bYtYmgII3ENd"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "WCt-ntOP3ENd"
   },
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "-rhq-TSh3ENd"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntYqVxEQ3ENd"
   },
   "source": [
    "**Question 2:** Create a dictionary to store the type and number of unique characters in the paragraph provided"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NOGImZ6c3ENd"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LlZ8GC4J3ENe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({' ': 192, 'e': 89, 'o': 68, 't': 65, 'i': 60, 's': 57, 'a': 48, 'r': 45, 'n': 42, 'l': 35, 'c': 31, 'd': 27, 'f': 26, 'u': 26, '0': 22, 'm': 20, 'y': 19, 'h': 17, 'w': 16, 'g': 14, '3': 13, '.': 12, 'p': 11, 'b': 11, '1': 11, '2': 10, '7': 10, 'k': 9, ',': 7, '4': 5, 'v': 4, '-': 4, '*': 4, '^': 4, 'T': 3, 'x': 3, '5': 3, '6': 3, '8': 3, '’': 3, '(': 3, ')': 3, 'q': 3, 'O': 3, ':': 2, '9': 2, 'S': 2, 'A': 2, '{': 2, '}': 2, '`': 2, 'I': 1, 'V': 1, 'F': 1, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '“': 1, '”': 1, '‘': 1, 'E': 1, '/': 1, '\\\\': 1})\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"The following is sample text I used to practice special characters using keybr.com: 112233445566778899 Saturn V rocket’s first stage carries 203,400 gallons (770,000 liters) of kerosene fuel and 318,000 gallons (1.2 million liters) of liquid oxygen needed for combustion. At liftoff, the stage’s five F-1 rocket engines ignite and produce 7.5 million pounds of thrust. To replace those goofy quantities with the far less retarded metric system (even though liters are considered part of the metric system they are the same as cubic deci-meters) you would say 770 cubic meters of kerosene {abbreviated as m3} and 1,204 m3 of liquid O2 [O2 is the symbol for oxygen]. We would also say it produced 33,600,000 newtons of force <abbreviated as N>. To add scientific notation {a way of writing numbers that allows you to write only as many digits `of specificity` as you would like} you can write 7.7 * 10 ^ 2 m3 of kerosene 1.204 * 10 ^ 3 m3 of O2 and 3.3 * 10 ^ 7 newtons. Another way to write scientific notation is to replace the “* 10 ^” with ‘E’ -/capital e\\-. So our numbers would look like:s\"\n",
    "# BEGIN SOLUTION\n",
    "from collections import Counter \n",
    "dictionary = Counter(paragraph)\n",
    "# END SOLUTION\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ZMHF82883ENe"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "qGIB-11l3ENe"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CP4wqwWV3ENe"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_dictionary(Counter):\n",
    "    assert Counter(paragraph) == {' ': 192, 'e': 89, 'o': 68, 't': 65, 'i': 60, 's': 57, 'a': 48, 'r': 45, 'n': 42, 'l': 35, 'c': 31, 'd': 27, 'f': 26, 'u': 26, '0': 22, 'm': 20, 'y': 19, 'h': 17, 'w': 16, 'g': 14, '3': 13, '.': 12, 'p': 11, 'b': 11, '1': 11, '2': 10, '7': 10, 'k': 9, ',': 7, '4': 5, 'v': 4, '-': 4, '*': 4, '^': 4, 'T': 3, 'x': 3, '5': 3, '6': 3, '8': 3, '’': 3, '(': 3, ')': 3, 'q': 3, 'O': 3, ':': 2, '9': 2, 'S': 2, 'A': 2, '{': 2, '}': 2, '`': 2, 'I': 1, 'V': 1, 'F': 1, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '“': 1, '”': 1, '‘': 1, 'E': 1, '/': 1, '\\\\': 1}\n",
    "test_dictionary(Counter)  # IGNORE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWfRARkE3ENe"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "sRzpWlU63ENe"
   },
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "OcdDoYHo3ENe"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylvPVW8m3ENe"
   },
   "source": [
    "**Question 3:** Extract the values from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "FEq77ujs2nOZ"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "I50ccd1SJMn4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\']\n"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "keysList = list(dictionary.keys()) \n",
    "# END SOLUTION\n",
    "print (keysList)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "AlBvbY8y3mzV"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cSTiSuKN3mzW"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TY8fZw062nOZ"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_keyslist():\n",
    "    assert list(dictionary.keys()) == ['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\']\n",
    "test_keyslist() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zDnw0nCz3wqF"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tHcVR_3j3wqG"
   },
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "6ELH7pQ_2nOa"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hucvAvprJMn5"
   },
   "source": [
    "**Question 4:** Extract the keys from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Qes2HItd2nOa"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wLHoBNERJMn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "valuesList = list(dictionary.values()) \n",
    "# END SOLUTION\n",
    "print (valuesList)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "x8qGI7gi2nOa"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cdyzKGlN2nOa"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_valueslist():\n",
    "    assert list(dictionary.values()) == [3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1]\n",
    "test_valueslist()  # IGNORE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "7lt8vzzM2nOa"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "aWa5fdyi2nOa"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PpnMsGpJMn5"
   },
   "source": [
    "**Question 5:** Merge the two lists into a tuple"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UDWWh3vQJMn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "keys_tuple = tuple(keysList)\n",
    "values_tuple = tuple(valuesList)\n",
    "final_tuple = (keys_tuple, values_tuple)\n",
    "# END SOLUTION\n",
    "print(final_tuple)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1Aeg14Gw2nOb"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AiIqLg5-2nOb"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_tuple():\n",
    "    assert final_tuple == (('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n",
    "test_tuple() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "CruivWVY2nOb"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION \n",
    "name: q6\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:**  Write a function `greatest_common_divisor` that takes two inputs `a` and `b` and returns the greatest common divisor of the two numbers. E.g. input `(10, 15)` would return `5`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greatest_common_divisor(a, b):\n",
    "    # BEGIN SOLUTION\n",
    "    aa = a if a < b else b\n",
    "    divisors = [i for i in range(1, aa+1) if a % i == 0 and b % i == 0]\n",
    "    return divisors[-1]\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(greatest_common_divisor(10, 15), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(15, 19), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(100, 105), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(4, 2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(20, 16), 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q7\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:**  Write a function `get_nearest_farthest` that takes in a point of interest (pt) and a list of points and returns the nearest point and the farthest point from the point of intest."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_farthest(pt, ptlist):\n",
    "    # BEGIN SOLUTION\n",
    "    def dist(a, b):\n",
    "        x1, y1 = a\n",
    "        x2, y2 = b\n",
    "        return math.sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
    "    \n",
    "    pts = sorted([(ptt, dist(pt, ptt)) for ptt in ptlist], key=lambda tp: tp[1])\n",
    "    return pts[0][0], pts[-1][0]\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(get_nearest_farthest((3, 8), [(9, 3), (8,5), (7,6)]), ((7, 6), (9, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((12,8), [(5,9), (9,1), (2,4), (13,9), (10,12)]), ((13, 9), (2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((5,8), [(5,9), (9,1), (2,4), (13,9), (10,12)]), ((5, 9), (13, 9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((12,2), [(5,9), (9,1), (2,4), (13,9), (10,12)]), ((9, 1), (10, 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((12, 2), [(9, 3), (8,5), (7,6)]), ((9, 3), (7, 6)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q8\n",
    "points: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:**  Write a function `perfectly_divisible` to return a list of numbers between 0 and a number $N$ that are perfectly divisible by $q$ (with out leaving a remainder). <br>\n",
    "**Hint**: $N$ should also be inclusive in the numbers being considered. If N is negative use N == 20"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfectly_divisible(N, q):\n",
    "    # BEGIN SOLUTION\n",
    "    N = 20 if N < 0 else N\n",
    "    return [num for num in range(N+1) if num%q == 0]\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(perfectly_divisible(10,2), [0,2,4,6,8,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(-10,2), [0,2,4,6,8,10,12,14,16,18,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(6,4), [0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(-6,4), [0, 4, 8, 12, 16, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(56,24), [0, 24, 48])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q9\n",
    "points: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:**  Write a function `flatten_lists` that takes in a list of lists and outputs a sorted list of elements of sublists of the input list (confusing right?) <br>\n",
    "Example: given `flatten_lists([[2,13,44], [6,7]])` it should return `[2,6,7,13,44]`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_lists(superlist):\n",
    "    # BEGIN SOLUTION\n",
    "    answer = []\n",
    "    for i in superlist:\n",
    "        for j in i:\n",
    "            answer.append(j)\n",
    "    return sorted(answer)\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(flatten_lists([[2,13,44], [6,7]]), [2, 6, 7, 13, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(flatten_lists([[2], [61,34,5,8,9]]), [2, 5, 8, 9, 34, 61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(flatten_lists([[3,2,1,5], [8,9], [5,4,4,6]]), [1, 2, 3, 4, 4, 5, 5, 6, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(flatten_lists([[3,2,1,5], [8,9], [5,4,4,6], [3]]), [1, 2, 3, 3, 4, 4, 5, 5, 6, 8, 9])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Extra Mile!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_egf664jJMn5"
   },
   "source": [
    "**Download the dataset \"Nakuru Sensor Data for February 2023 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/14165682-37dd-4f40-914e-eb24619e4ef8\"**\n",
    "\n",
    "Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "r2lE0yrPJMn5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Nakuru_Sensor_Data_Feb_2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNakuru_Sensor_Data_Feb_2023.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsa/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsa/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsa/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsa/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/dsa/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsa/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/dsa/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Nakuru_Sensor_Data_Feb_2023.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "#Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe \n",
    "\n",
    "df = pd.read_csv(r'Nakuru_Sensor_Data_Feb_2023.csv',usecols=['timestamp','value_type','value'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er6lemMeJMn5"
   },
   "source": [
    "**Question E1:** Create a new collumn 'timestamp_new' from 'timestamp' rounded off to the second "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "sQq3JIaVJMn5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# BEGIN SOLUTION\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], infer_datetime_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp_new\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# SOLUTION\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# END SOLUTION\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True)\n",
    "df['timestamp_new'] = df['timestamp'].dt.floor('S') # SOLUTION\n",
    "# END SOLUTION\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HM8DysCJMn6"
   },
   "source": [
    "**Question E2:** Split the dataframe based on the 'value_type' collumn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "z3NUYMOZJMn6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grouped \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(df\u001b[38;5;241m.\u001b[39mvalue_type) \u001b[38;5;66;03m# SOLUTION\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_temperature \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39mget_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# SOLUTION\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df_humidity \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39mget_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhumidity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# SOLUTION\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby(df.value_type) # SOLUTION\n",
    "df_temperature = grouped.get_group(\"temperature\") # SOLUTION\n",
    "df_humidity = grouped.get_group(\"humidity\") # SOLUTION\n",
    "df_P1 = grouped.get_group(\"P1\") # SOLUTION\n",
    "df_P2 = grouped.get_group(\"P2\") # SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAEsAuUvJMn6"
   },
   "source": [
    "**Question E3:** Find the mean, mode and median of the humidity, temperature, P1 and P2 values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "14T6jzZ_JMn6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_temperature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# BEGIN SOLUTION\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mu_temp, med_temp, sd_temp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mdf_temperature\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]), np\u001b[38;5;241m.\u001b[39mmedian(df_temperature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]), np\u001b[38;5;241m.\u001b[39mstd(df_temperature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# END SOLUTION\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_temperature' is not defined"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "mu_temp, med_temp, sd_temp = np.mean(df_temperature['value']), np.median(df_temperature['value']), np.std(df_temperature['value'])\n",
    "# END SOLUTION\n",
    "print(\"Temperature\")\n",
    "print(\"Mean = \",mu_temp, \"Median = \", med_temp, \"Standard Deviation = \", sd_temp)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "mu_humidity, med_humidity, sd_humidity = np.mean(df_humidity['value']), np.median(df_humidity['value']), np.std(df_humidity['value'])\n",
    "# END SOLUTION\n",
    "print(\"Humidity\")\n",
    "print(\"Mean = \",mu_humidity, \"Median = \", med_humidity, \"Standard Deviation = \", sd_humidity)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "mu_P1, med_P1, sd_P1 = np.mean(df_P1['value']), np.median(df_P1['value']), np.std(df_P1['value'])\n",
    "# END SOLUTION\n",
    "print(\"P1\")\n",
    "print(\"Mean = \",mu_P1, \"Median = \", med_P1, \"Standard Deviation = \", sd_P1)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "mu_P2, med_P2, sd_P2 = np.mean(df_P2['value']), np.median(df_P2['value']), np.std(df_P2['value'])\n",
    "# END SOLUTION\n",
    "print(\"P2\")\n",
    "print(\"Mean = \",mu_P2, \"Median = \", med_P2, \"Standard Deviation = \", sd_P2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKWBykh-JMn6"
   },
   "source": [
    "**Question E4:** Merge the grouped dataframes into one dataframe and save it as newdata.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "4mQSIPfhJMn6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_temperature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# BEGIN SOLUTION\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m \u001b[43mdf_temperature\u001b[49m\u001b[38;5;241m.\u001b[39mmerge(df_humidity,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp_new\u001b[39m\u001b[38;5;124m'\u001b[39m,suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_temperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_humidity\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mmerge(df_P1,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp_new\u001b[39m\u001b[38;5;124m'\u001b[39m,suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_prev\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_P1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mmerge(df_P2,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp_new\u001b[39m\u001b[38;5;124m'\u001b[39m,suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_P1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_P2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_temperature' is not defined"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "df_merged = df_temperature.merge(df_humidity,how='left', on='timestamp_new',suffixes=('_temperature', '_humidity'))\n",
    "df_merged = df_merged.merge(df_P1,how='left', on='timestamp_new',suffixes=('_prev', '_P1'))\n",
    "df_merged = df_merged.merge(df_P2,how='left', on='timestamp_new',suffixes=('_P1', '_P2'))\n",
    "# END SOLUTION\n",
    "print(df_merged)\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('newdata.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_merged.to_csv(filepath)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNLVvAvbJMn6"
   },
   "source": [
    "**Question E5:** Open the new data file and select only 'timestamp_new','value_temperature','value_humidity','value_P1' and 'value_P2' collunms"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fyxaLq2JMn6"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "new_df = pd.read_csv(r'newdata.csv',usecols=['timestamp_new','value_temperature','value_humidity','value_P1','value_P2'])\n",
    "# END SOLUTION\n",
    "new_df "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh5va_ODJMn6"
   },
   "source": [
    "**Question E6:** Replace the missing values in collumns 'value_P1' and 'value_P2' with the mean of the same collumns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAm29MW0JMn7"
   },
   "outputs": [],
   "source": [
    "#Check for missing values \n",
    "missing_values = pd.isnull(new_df['value_P1']) # SOLUTION\n",
    "\n",
    "# displaying data only with NaN\n",
    "new_df[missing_values] # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJ2zFruYJMn7"
   },
   "outputs": [],
   "source": [
    "#print(\"The mean of P1\",new_df['value_P2'].mean())\n",
    "#print(\"The mean of P2\",new_df['value_P1'].mean())\n",
    "\n",
    "#replace missing values with the mean \n",
    "# BEGIN SOLUTION\n",
    "new_df['value_P1'].fillna(new_df['value_P1'].mean(), inplace=True) \n",
    "new_df['value_P2'].fillna(new_df['value_P2'].mean(), inplace=True) \n",
    "# BEGIN SOLUTION\n",
    "\n",
    "#Check for missing values after the replacement operation \n",
    "missing_values = pd.isnull(new_df['value_P2']) # SOLUTION\n",
    "\n",
    "# displaying data only with NaN (if any) after the replacement operation \n",
    "# BEGIN SOLUTION\n",
    "new_df[missing_values] \n",
    "# END SOLUTION\n",
    "new_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syjHmz-AJMn7"
   },
   "source": [
    "**Question E7:** Compute the correlations between temperature and humidity; P1 and P2 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agvSVKsEJMn7"
   },
   "outputs": [],
   "source": [
    "#Correlation between temperature and humidity\n",
    "# BEGIN SOLUTION\n",
    "corr_temp_hum = new_df['value_temperature'].corr(new_df['value_humidity'])\n",
    "# END SOLUTION\n",
    "\n",
    "print (\"Correlation between temparature and humidity\",corr_temp_hum)\n",
    "\n",
    "#Correlation between P1 and P2\n",
    "# BEGIN SOLUTION\n",
    "corr_p1_p2 = new_df['value_P1'].corr(new_df['value_P2'])\n",
    "# END SOLUTION\n",
    "\n",
    "print (\"Correlation between P1 and P2\",corr_p1_p2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIy00VyKJMn7"
   },
   "source": [
    "**Question E8:** Create a new dataframe comprising of the average values of the variables by day"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb_G74GPJMn7"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "new_df['timestamp_new'] = pd.to_datetime(df['timestamp_new'], infer_datetime_format=True) \n",
    "new_df['timestamp_new'] = df['timestamp_new'].dt.floor('D')  \n",
    "# END SOLUTION\n",
    "means_feb = new_df.groupby('timestamp_new').mean() # SOLUTION\n",
    "means_feb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXrFVTUPJMn7"
   },
   "source": [
    "**Question E9:** Download the dataset \"Nakuru Sensor Data for November 2021 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/1f11351e-156b-4e4c-a063-b86a6ee07c4a\"\n",
    "\n",
    "Load the data into a pandas dataframe and develop a dataframe similar to what you have just done in Question no's 6 - 13 above"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooqx8xuoJMn7"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "#Import only the 'timestamp','value_type'and'value' collumns \n",
    "df_nov = pd.read_csv(r'Nakuru_Sensor_Data_Nov_2021.csv',sep = ';') \n",
    "\n",
    "#Create a new collumn 'timestamp_new' from 'timestamp' rounded off to the second\n",
    "df_nov['timestamp'] = pd.to_datetime(df_nov['timestamp'], infer_datetime_format=True)\n",
    "df_nov['timestamp_new'] = df_nov['timestamp'].dt.floor('S')\n",
    "\n",
    "#Group the data by value_type \n",
    "grouped_nov = df_nov.groupby(df_nov.value_type)\n",
    "df_temperature_nov = grouped_nov.get_group(\"temperature\")\n",
    "df_humidity_nov = grouped_nov.get_group(\"humidity\")\n",
    "df_P1_nov = grouped_nov.get_group(\"P1\")\n",
    "df_P2_nov= grouped_nov.get_group(\"P2\")\n",
    "\n",
    "#print(\"New timestamp\",df_P2_nov['timestamp_new'])\n",
    "\n",
    "#Create a new dataframe by merging the grouped data frames \n",
    "df_merged_nov = df_temperature_nov.merge(df_humidity_nov,how='left', on='timestamp_new',suffixes=('_temperature', '_humidity'))\n",
    "df_merged_nov = df_merged_nov.merge(df_P1_nov,how='left', on='timestamp_new',suffixes=('_prev', '_P1'))\n",
    "df_merged_nov = df_merged_nov.merge(df_P2_nov,how='left', on='timestamp_new',suffixes=('_P1', '_P2'))\n",
    "#print(\"Merged November - \",df_merged_nov)\n",
    "\n",
    "#Open the new file \n",
    "from pathlib import Path  \n",
    "filepath = Path('newdata_nov.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_merged_nov.to_csv(filepath)  \n",
    "\n",
    "new_df_nov = pd.read_csv(r'newdata_nov.csv',usecols=['timestamp_new','value_temperature','value_humidity','value_P1','value_P2'])\n",
    "#new_df_nov \n",
    "\n",
    "#replace missing values with the mean \n",
    "new_df_nov['value_P1'].fillna(new_df_nov['value_P1'].mean(), inplace=True) \n",
    "new_df_nov['value_P2'].fillna(new_df_nov['value_P2'].mean(), inplace=True) \n",
    "\n",
    "#Create a new dataframe comprising of the average values of the variables by day\n",
    "new_df_nov['timestamp_new'] = pd.to_datetime(new_df_nov['timestamp_new'], infer_datetime_format=True)\n",
    "new_df_nov['timestamp_new'] = new_df_nov['timestamp_new'].dt.floor('D')\n",
    "# END SOLUTION\n",
    "means_nov = new_df_nov.groupby('timestamp_new').mean() # SOLUTION\n",
    "means_nov"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7RRkZpnYqa"
   },
   "source": [
    "**Question E10:** Convert the means_feb and means_nov to numpy arrays ... and then compute the average of each collumn\n",
    "\n",
    "Hint: The results are numpy arrays"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbgK6RQ8nDXw"
   },
   "outputs": [],
   "source": [
    "feb_numpy_array = means_feb.to_numpy() # SOLUTION\n",
    "feb_average = np.mean(feb_numpy_array, axis = 0) # SOLUTION\n",
    "feb_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6-iwnWSoIDE"
   },
   "outputs": [],
   "source": [
    "nov_numpy_array = means_nov.to_numpy() # SOLUTION\n",
    "nov_average = np.mean(nov_numpy_array, axis = 0) # SOLUTION\n",
    "nov_average"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc6tiksMqSb0"
   },
   "source": [
    "**Question E11:** Write a function to compute the difference in the average temperature, humidity, P1 and P2 between November 2021 and February 2023\n",
    "\n",
    "Hint: The result is a vector of the form [w,x,y,z]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWCrhXpKqPJQ"
   },
   "outputs": [],
   "source": [
    "def sub():\n",
    "    # BEGIN SOLUTION\n",
    "    diff = []\n",
    "    for i in range(len(nov_average)):\n",
    "        result = nov_average[i] - feb_average[i]\n",
    "        diff.append(result)\n",
    "    # END SOLUTION\n",
    "    return diff\n",
    " \n",
    "# Print the result of the subtraction\n",
    "difference = sub()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "kGsZ_oD43ENf"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
