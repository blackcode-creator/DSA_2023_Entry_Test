{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ASSIGNMENT CONFIG\n",
    "requirements: requirements.txt\n",
    "solutions_pdf: true\n",
    "export_cell:\n",
    "    instructions: \"Upload the generated zip file to the Google sheet please. Uploading work which is not yours will lead to non admittance.\"\n",
    "generate: \n",
    "    pdf: false\n",
    "    filtering: false\n",
    "    pagebreaks: true\n",
    "    zips: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1DroRwx3ENZ"
   },
   "source": [
    "## DSA 2023 Summer School Admittance Check\n",
    "\n",
    "Thanks for your interest in attending DSA Kigali 2023. To attend the summer school you have to have some level of basic Python proficiency. Completing the following notebook should ensure you have the right kind of background to benefit maximally from the Summer School. See you in Kigali!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Upwjh9U3ENa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ipython\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Import the good stuff\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Run these once ... Just in case \n",
    "#!pip install nose \n",
    "#!pip install otter-grader\n",
    "import IPython\n",
    "from IPython import get_ipython\n",
    "# Import the good stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nose.tools import assert_equal\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "vBJliosn3ENc"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ibmmx8r3ENc"
   },
   "source": [
    "**Question 1:** Write a Python function to return a tuple of primes and non primes given an integer input "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "EXaFYdNh3ENc"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWjGPqaO3ENc"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def sieve(num):\n",
    "    prime = [True for i in range(num+1)]\n",
    "    prime_list = []\n",
    "    not_prime_list = []\n",
    "    \n",
    "    # boolean array\n",
    "    p = 2\n",
    "    while (p * p <= num):\n",
    "\n",
    "        # If prime[p] is not\n",
    "        # changed, then it is a prime\n",
    "        if (prime[p] == True):\n",
    "\n",
    "            # Updating all multiples of p\n",
    "            for i in range(p * p, num+1, p):\n",
    "                prime[i] = False\n",
    "        p += 1\n",
    "   \n",
    "    p = 2\n",
    "    # Create the lists \n",
    "    for p in range(2, num+1):\n",
    "        if prime[p]:\n",
    "            prime_list.append(p)\n",
    "        else: \n",
    "            not_prime_list.append(p)\n",
    "   \n",
    "    # Create the tuple \n",
    "    prime_list_tuple = tuple(prime_list)\n",
    "    not_prime_list_tuple = tuple(not_prime_list)\n",
    "    return_tuple = (prime_list_tuple, not_prime_list_tuple)\n",
    "    return(return_tuple)\n",
    "# END SOLUTION\n",
    "num = 30\n",
    "print(\"Following are the prime and non prime numbers smaller than or equal to\", num)\n",
    "print(sieve(num))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "WELGXYcy3ENc"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "-l5Dzy2t3ENc"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpVT1y5y3ENd"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_primes(sieve):\n",
    "    assert sieve(30) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n",
    "test_primes(sieve)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk8NLc_-3ENd"
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "def test_higher_primes(sieve):\n",
    "    assert sieve(100) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100))\n",
    "    assert sieve(200) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 164, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 194, 195, 196, 198, 200))\n",
    "test_higher_primes(sieve) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "bYtYmgII3ENd"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "WCt-ntOP3ENd"
   },
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "-rhq-TSh3ENd"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntYqVxEQ3ENd"
   },
   "source": [
    "**Question 2:** Create a dictionary to store the type and number of unique characters in the paragraph provided"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NOGImZ6c3ENd"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlZ8GC4J3ENe"
   },
   "outputs": [],
   "source": [
    "paragraph = \"The following is sample text I used to practice special characters using keybr.com: 112233445566778899 Saturn V rocket’s first stage carries 203,400 gallons (770,000 liters) of kerosene fuel and 318,000 gallons (1.2 million liters) of liquid oxygen needed for combustion. At liftoff, the stage’s five F-1 rocket engines ignite and produce 7.5 million pounds of thrust. To replace those goofy quantities with the far less retarded metric system (even though liters are considered part of the metric system they are the same as cubic deci-meters) you would say 770 cubic meters of kerosene {abbreviated as m3} and 1,204 m3 of liquid O2 [O2 is the symbol for oxygen]. We would also say it produced 33,600,000 newtons of force <abbreviated as N>. To add scientific notation {a way of writing numbers that allows you to write only as many digits `of specificity` as you would like} you can write 7.7 * 10 ^ 2 m3 of kerosene 1.204 * 10 ^ 3 m3 of O2 and 3.3 * 10 ^ 7 newtons. Another way to write scientific notation is to replace the “* 10 ^” with ‘E’ -/capital e\\-. So our numbers would look like:s\"\n",
    "# BEGIN SOLUTION\n",
    "from collections import Counter \n",
    "dictionary = Counter(paragraph)\n",
    "# END SOLUTION\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ZMHF82883ENe"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "qGIB-11l3ENe"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CP4wqwWV3ENe"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_dictionary(Counter):\n",
    "    assert Counter(paragraph) == {' ': 192, 'e': 89, 'o': 68, 't': 65, 'i': 60, 's': 57, 'a': 48, 'r': 45, 'n': 42, 'l': 35, 'c': 31, 'd': 27, 'f': 26, 'u': 26, '0': 22, 'm': 20, 'y': 19, 'h': 17, 'w': 16, 'g': 14, '3': 13, '.': 12, 'p': 11, 'b': 11, '1': 11, '2': 10, '7': 10, 'k': 9, ',': 7, '4': 5, 'v': 4, '-': 4, '*': 4, '^': 4, 'T': 3, 'x': 3, '5': 3, '6': 3, '8': 3, '’': 3, '(': 3, ')': 3, 'q': 3, 'O': 3, ':': 2, '9': 2, 'S': 2, 'A': 2, '{': 2, '}': 2, '`': 2, 'I': 1, 'V': 1, 'F': 1, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '“': 1, '”': 1, '‘': 1, 'E': 1, '/': 1, '\\\\': 1}\n",
    "test_dictionary(Counter)  # IGNORE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWfRARkE3ENe"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "sRzpWlU63ENe"
   },
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "OcdDoYHo3ENe"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylvPVW8m3ENe"
   },
   "source": [
    "**Question 3:** Extract the values from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "FEq77ujs2nOZ"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I50ccd1SJMn4"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "keysList = list(dictionary.keys()) \n",
    "# END SOLUTION\n",
    "print (keysList)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "AlBvbY8y3mzV"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cSTiSuKN3mzW"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TY8fZw062nOZ"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_keyslist():\n",
    "    assert list(dictionary.keys()) == ['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\']\n",
    "test_keyslist() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zDnw0nCz3wqF"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tHcVR_3j3wqG"
   },
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "6ELH7pQ_2nOa"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hucvAvprJMn5"
   },
   "source": [
    "**Question 4:** Extract the keys from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Qes2HItd2nOa"
   },
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLHoBNERJMn5"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "valuesList = list(dictionary.values()) \n",
    "# END SOLUTION\n",
    "print (valuesList)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "x8qGI7gi2nOa"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdyzKGlN2nOa"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_valueslist():\n",
    "    assert list(dictionary.values()) == [3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1]\n",
    "test_valueslist()  # IGNORE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "7lt8vzzM2nOa"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "aWa5fdyi2nOa"
   },
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PpnMsGpJMn5"
   },
   "source": [
    "**Question 5:** Merge the two lists into a tuple"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDWWh3vQJMn5"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "keys_tuple = tuple(keysList)\n",
    "values_tuple = tuple(valuesList)\n",
    "final_tuple = (keys_tuple, values_tuple)\n",
    "# END SOLUTION\n",
    "print(final_tuple)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1Aeg14Gw2nOb"
   },
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiIqLg5-2nOb"
   },
   "outputs": [],
   "source": [
    "# BEGIN TEST CONFIG\n",
    "points: 2\n",
    "# END TEST CONFIG\n",
    "def test_tuple():\n",
    "    assert final_tuple == (('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '’', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '“', '”', '‘', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n",
    "test_tuple() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "CruivWVY2nOb"
   },
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION \n",
    "name: q6\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:**  Write a function `greatest_common_divisor` that takes two inputs `a` and `b` and returns the greatest common divisor of the two numbers. E.g. input `(10, 15)` would return `5`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greatest_common_divisor(a, b):\n",
    "    # BEGIN SOLUTION\n",
    "    aa = a if a < b else b\n",
    "    divisors = [i for i in range(1, aa+1) if a % i == 0 and b % i == 0]\n",
    "    return divisors[-1]\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(greatest_common_divisor(10, 15), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(15, 19), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(100, 105), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(4, 2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(greatest_common_divisor(20, 16), 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q7\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:**  Write a function `get_nearest_farthest` that takes in a point of interest (pt) and a list of points and returns the nearest point and the farthest point from the point of intest."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_farthest(pt, ptlist):\n",
    "    # BEGIN SOLUTION\n",
    "    def dist(a, b):\n",
    "        x1, y1 = a\n",
    "        x2, y2 = b\n",
    "        return math.sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
    "    \n",
    "    pts = sorted([(ptt, dist(pt, ptt)) for ptt in ptlist], key=lambda tp: tp[1])\n",
    "    return pts[0][0], pts[-1][0]\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(get_nearest_farthest((3, 8), [(9, 3), (8,5), (7,6)]), ((7, 6), (9, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((12,8), [(5,9), (9,1), (2,4), (13,9), (10,12)]), ((13, 9), (2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((5,8), [(5,9), (9,1), (2,4), (13,9), (10,12)]), ((5, 9), (13, 9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((12,2), [(5,9), (9,1), (2,4), (13,9), (10,12)]), ((9, 1), (10, 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(get_nearest_farthest((12, 2), [(9, 3), (8,5), (7,6)]), ((9, 3), (7, 6)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q8\n",
    "points: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:**  Write a function `perfectly_divisible` to return a list of numbers between 0 and a number $N$ that are perfectly divisible by $q$ (with out leaving a remainder). <br>\n",
    "**Hint**: $N$ should also be inclusive in the numbers being considered. If N is negative use N == 20"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfectly_divisible(N, q):\n",
    "    # BEGIN SOLUTION\n",
    "    N = 20 if N < 0 else N\n",
    "    return [num for num in range(N+1) if num%q == 0]\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(perfectly_divisible(10,2), [0,2,4,6,8,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(-10,2), [0,2,4,6,8,10,12,14,16,18,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(6,4), [0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(-6,4), [0, 4, 8, 12, 16, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(perfectly_divisible(56,24), [0, 24, 48])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q9\n",
    "points: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:**  Write a function `flatten_lists` that takes in a list of lists and outputs a sorted list of elements of sublists of the input list (confusing right?) <br>\n",
    "Example: given `flatten_lists([[2,13,44], [6,7]])` it should return `[2,6,7,13,44]`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_lists(superlist):\n",
    "    # BEGIN SOLUTION\n",
    "    answer = []\n",
    "    for i in superlist:\n",
    "        for j in i:\n",
    "            answer.append(j)\n",
    "    return sorted(answer)\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(flatten_lists([[2,13,44], [6,7]]), [2, 6, 7, 13, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(flatten_lists([[2], [61,34,5,8,9]]), [2, 5, 8, 9, 34, 61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(flatten_lists([[3,2,1,5], [8,9], [5,4,4,6]]), [1, 2, 3, 4, 4, 5, 5, 6, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert_equal(flatten_lists([[3,2,1,5], [8,9], [5,4,4,6], [3]]), [1, 2, 3, 3, 4, 4, 5, 5, 6, 8, 9])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Extra Mile!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_egf664jJMn5"
   },
   "source": [
    "**Download the dataset \"Nakuru Sensor Data for February 2023 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/14165682-37dd-4f40-914e-eb24619e4ef8\"**\n",
    "\n",
    "Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2lE0yrPJMn5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "#Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe \n",
    "\n",
    "df = pd.read_csv(r'Nakuru_Sensor_Data_Feb_2023.csv',usecols=['timestamp','value_type','value'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er6lemMeJMn5"
   },
   "source": [
    "**Question E1:** Create a new collumn 'timestamp_new' from 'timestamp' rounded off to the second "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQq3JIaVJMn5"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True)\n",
    "df['timestamp_new'] = df['timestamp'].dt.floor('S') # SOLUTION\n",
    "# END SOLUTION\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HM8DysCJMn6"
   },
   "source": [
    "**Question E2:** Split the dataframe based on the 'value_type' collumn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3NUYMOZJMn6"
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(df.value_type) # SOLUTION\n",
    "df_temperature = grouped.get_group(\"temperature\") # SOLUTION\n",
    "df_humidity = grouped.get_group(\"humidity\") # SOLUTION\n",
    "df_P1 = grouped.get_group(\"P1\") # SOLUTION\n",
    "df_P2 = grouped.get_group(\"P2\") # SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAEsAuUvJMn6"
   },
   "source": [
    "**Question E3:** Find the mean, mode and median of the humidity, temperature, P1 and P2 values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14T6jzZ_JMn6"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "mu_temp, med_temp, sd_temp = np.mean(df_temperature['value']), np.median(df_temperature['value']), np.std(df_temperature['value'])\n",
    "# END SOLUTION\n",
    "print(\"Temperature\")\n",
    "print(\"Mean = \",mu_temp, \"Median = \", med_temp, \"Standard Deviation = \", sd_temp)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "mu_humidity, med_humidity, sd_humidity = np.mean(df_humidity['value']), np.median(df_humidity['value']), np.std(df_humidity['value'])\n",
    "# END SOLUTION\n",
    "print(\"Humidity\")\n",
    "print(\"Mean = \",mu_humidity, \"Median = \", med_humidity, \"Standard Deviation = \", sd_humidity)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "mu_P1, med_P1, sd_P1 = np.mean(df_P1['value']), np.median(df_P1['value']), np.std(df_P1['value'])\n",
    "# END SOLUTION\n",
    "print(\"P1\")\n",
    "print(\"Mean = \",mu_P1, \"Median = \", med_P1, \"Standard Deviation = \", sd_P1)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "mu_P2, med_P2, sd_P2 = np.mean(df_P2['value']), np.median(df_P2['value']), np.std(df_P2['value'])\n",
    "# END SOLUTION\n",
    "print(\"P2\")\n",
    "print(\"Mean = \",mu_P2, \"Median = \", med_P2, \"Standard Deviation = \", sd_P2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKWBykh-JMn6"
   },
   "source": [
    "**Question E4:** Merge the grouped dataframes into one dataframe and save it as newdata.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mQSIPfhJMn6"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "df_merged = df_temperature.merge(df_humidity,how='left', on='timestamp_new',suffixes=('_temperature', '_humidity'))\n",
    "df_merged = df_merged.merge(df_P1,how='left', on='timestamp_new',suffixes=('_prev', '_P1'))\n",
    "df_merged = df_merged.merge(df_P2,how='left', on='timestamp_new',suffixes=('_P1', '_P2'))\n",
    "# END SOLUTION\n",
    "print(df_merged)\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('newdata.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_merged.to_csv(filepath)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNLVvAvbJMn6"
   },
   "source": [
    "**Question E5:** Open the new data file and select only 'timestamp_new','value_temperature','value_humidity','value_P1' and 'value_P2' collunms"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fyxaLq2JMn6"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "new_df = pd.read_csv(r'newdata.csv',usecols=['timestamp_new','value_temperature','value_humidity','value_P1','value_P2'])\n",
    "# END SOLUTION\n",
    "new_df "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh5va_ODJMn6"
   },
   "source": [
    "**Question E6:** Replace the missing values in collumns 'value_P1' and 'value_P2' with the mean of the same collumns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAm29MW0JMn7"
   },
   "outputs": [],
   "source": [
    "#Check for missing values \n",
    "missing_values = pd.isnull(new_df['value_P1']) # SOLUTION\n",
    "\n",
    "# displaying data only with NaN\n",
    "new_df[missing_values] # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJ2zFruYJMn7"
   },
   "outputs": [],
   "source": [
    "#print(\"The mean of P1\",new_df['value_P2'].mean())\n",
    "#print(\"The mean of P2\",new_df['value_P1'].mean())\n",
    "\n",
    "#replace missing values with the mean \n",
    "# BEGIN SOLUTION\n",
    "new_df['value_P1'].fillna(new_df['value_P1'].mean(), inplace=True) \n",
    "new_df['value_P2'].fillna(new_df['value_P2'].mean(), inplace=True) \n",
    "# BEGIN SOLUTION\n",
    "\n",
    "#Check for missing values after the replacement operation \n",
    "missing_values = pd.isnull(new_df['value_P2']) # SOLUTION\n",
    "\n",
    "# displaying data only with NaN (if any) after the replacement operation \n",
    "# BEGIN SOLUTION\n",
    "new_df[missing_values] \n",
    "# END SOLUTION\n",
    "new_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syjHmz-AJMn7"
   },
   "source": [
    "**Question E7:** Compute the correlations between temperature and humidity; P1 and P2 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agvSVKsEJMn7"
   },
   "outputs": [],
   "source": [
    "#Correlation between temperature and humidity\n",
    "# BEGIN SOLUTION\n",
    "corr_temp_hum = new_df['value_temperature'].corr(new_df['value_humidity'])\n",
    "# END SOLUTION\n",
    "\n",
    "print (\"Correlation between temparature and humidity\",corr_temp_hum)\n",
    "\n",
    "#Correlation between P1 and P2\n",
    "# BEGIN SOLUTION\n",
    "corr_p1_p2 = new_df['value_P1'].corr(new_df['value_P2'])\n",
    "# END SOLUTION\n",
    "\n",
    "print (\"Correlation between P1 and P2\",corr_p1_p2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIy00VyKJMn7"
   },
   "source": [
    "**Question E8:** Create a new dataframe comprising of the average values of the variables by day"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb_G74GPJMn7"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "new_df['timestamp_new'] = pd.to_datetime(df['timestamp_new'], infer_datetime_format=True) \n",
    "new_df['timestamp_new'] = df['timestamp_new'].dt.floor('D')  \n",
    "# END SOLUTION\n",
    "means_feb = new_df.groupby('timestamp_new').mean() # SOLUTION\n",
    "means_feb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXrFVTUPJMn7"
   },
   "source": [
    "**Question E9:** Download the dataset \"Nakuru Sensor Data for November 2021 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/1f11351e-156b-4e4c-a063-b86a6ee07c4a\"\n",
    "\n",
    "Load the data into a pandas dataframe and develop a dataframe similar to what you have just done in Question no's 6 - 13 above"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooqx8xuoJMn7"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "#Import only the 'timestamp','value_type'and'value' collumns \n",
    "df_nov = pd.read_csv(r'Nakuru_Sensor_Data_Nov_2021.csv',sep = ';') \n",
    "\n",
    "#Create a new collumn 'timestamp_new' from 'timestamp' rounded off to the second\n",
    "df_nov['timestamp'] = pd.to_datetime(df_nov['timestamp'], infer_datetime_format=True)\n",
    "df_nov['timestamp_new'] = df_nov['timestamp'].dt.floor('S')\n",
    "\n",
    "#Group the data by value_type \n",
    "grouped_nov = df_nov.groupby(df_nov.value_type)\n",
    "df_temperature_nov = grouped_nov.get_group(\"temperature\")\n",
    "df_humidity_nov = grouped_nov.get_group(\"humidity\")\n",
    "df_P1_nov = grouped_nov.get_group(\"P1\")\n",
    "df_P2_nov= grouped_nov.get_group(\"P2\")\n",
    "\n",
    "#print(\"New timestamp\",df_P2_nov['timestamp_new'])\n",
    "\n",
    "#Create a new dataframe by merging the grouped data frames \n",
    "df_merged_nov = df_temperature_nov.merge(df_humidity_nov,how='left', on='timestamp_new',suffixes=('_temperature', '_humidity'))\n",
    "df_merged_nov = df_merged_nov.merge(df_P1_nov,how='left', on='timestamp_new',suffixes=('_prev', '_P1'))\n",
    "df_merged_nov = df_merged_nov.merge(df_P2_nov,how='left', on='timestamp_new',suffixes=('_P1', '_P2'))\n",
    "#print(\"Merged November - \",df_merged_nov)\n",
    "\n",
    "#Open the new file \n",
    "from pathlib import Path  \n",
    "filepath = Path('newdata_nov.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_merged_nov.to_csv(filepath)  \n",
    "\n",
    "new_df_nov = pd.read_csv(r'newdata_nov.csv',usecols=['timestamp_new','value_temperature','value_humidity','value_P1','value_P2'])\n",
    "#new_df_nov \n",
    "\n",
    "#replace missing values with the mean \n",
    "new_df_nov['value_P1'].fillna(new_df_nov['value_P1'].mean(), inplace=True) \n",
    "new_df_nov['value_P2'].fillna(new_df_nov['value_P2'].mean(), inplace=True) \n",
    "\n",
    "#Create a new dataframe comprising of the average values of the variables by day\n",
    "new_df_nov['timestamp_new'] = pd.to_datetime(new_df_nov['timestamp_new'], infer_datetime_format=True)\n",
    "new_df_nov['timestamp_new'] = new_df_nov['timestamp_new'].dt.floor('D')\n",
    "# END SOLUTION\n",
    "means_nov = new_df_nov.groupby('timestamp_new').mean() # SOLUTION\n",
    "means_nov"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7RRkZpnYqa"
   },
   "source": [
    "**Question E10:** Convert the means_feb and means_nov to numpy arrays ... and then compute the average of each collumn\n",
    "\n",
    "Hint: The results are numpy arrays"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbgK6RQ8nDXw"
   },
   "outputs": [],
   "source": [
    "feb_numpy_array = means_feb.to_numpy() # SOLUTION\n",
    "feb_average = np.mean(feb_numpy_array, axis = 0) # SOLUTION\n",
    "feb_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6-iwnWSoIDE"
   },
   "outputs": [],
   "source": [
    "nov_numpy_array = means_nov.to_numpy() # SOLUTION\n",
    "nov_average = np.mean(nov_numpy_array, axis = 0) # SOLUTION\n",
    "nov_average"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q_E11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc6tiksMqSb0"
   },
   "source": [
    "**Question E11:** Write a function to compute the difference in the average temperature, humidity, P1 and P2 between November 2021 and February 2023\n",
    "\n",
    "Hint: The result is a vector of the form [w,x,y,z]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWCrhXpKqPJQ"
   },
   "outputs": [],
   "source": [
    "def sub():\n",
    "    # BEGIN SOLUTION\n",
    "    diff = []\n",
    "    for i in range(len(nov_average)):\n",
    "        result = nov_average[i] - feb_average[i]\n",
    "        diff.append(result)\n",
    "    # END SOLUTION\n",
    "    return diff\n",
    " \n",
    "# Print the result of the subtraction\n",
    "difference = sub()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "kGsZ_oD43ENf"
   },
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
